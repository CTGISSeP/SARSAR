{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c6bf5f",
   "metadata": {},
   "source": [
    "# B - Change date detection\n",
    "**REQUIREMENT : (A) and UPDATED SAR_INDEX_STATS TABLE**\n",
    "\n",
    "This program carries out change date detection using the following function:\n",
    "\n",
    ">**change_date_detection(sites, dteDebut, dteFin, dteExe)**\n",
    "\n",
    "For each SAR, this function operates the following steps:\n",
    "\n",
    "**1) Preparation of dataframes as input for change date detection**\n",
    "\n",
    "Dataframes consists of 4-year history of VH_[orbit] (3 different VH orbits by site) and NDWI2 (for each site).\n",
    "The 4-year history is defined be the user using dteDebut and dteFin parameters.\n",
    "\n",
    "**2) Change date detection** \n",
    "The module of change detection of ERM is used namely\n",
    "> **change_detection(profiles[,day_end])**\n",
    "\n",
    ">>Parameters:\n",
    "\n",
    ">>>profiles: list of pandas DataFrames\n",
    "\n",
    ">>>>All the (at least three) VH and NDWI2 temporal profiles available for a given site.\n",
    "\n",
    ">>>day_end: string (optional)\n",
    "\n",
    ">>>>Last day of analysis. Default is the day on which the routine is called. Format YYYY-MM-DD.\n",
    "\n",
    ">>Returns:\n",
    "\n",
    ">>>pandas DataFrame (change dates in [day_end-1Y, day_end-1M]) or 0 (if no change detection was performed)\n",
    "\n",
    ">>>pandas Dataframe (VH feature in [day_end-4Y, day_end]) or 0 (if no VH feature is available)\n",
    "\n",
    "Dataframes generated in 1) are provided as input.\n",
    "\n",
    "Dataframes are processed by the module namely VH orbits are combined into one single VH signal. Gaps in VH and NDWI2 are filled and the resulted time-series are smoothed using a gaussian filter.\n",
    "\n",
    "Change date are then using the smoothed VH and NDWI2 4-year time series calculated.\n",
    "\n",
    "Change date are returned for the last year of the 4-year period minus one month .\n",
    "\n",
    "The date (dteChgEnd = dteFin -1 month)\n",
    "\n",
    "**3) Output are saved in tables**\n",
    "\n",
    "Change dates are saved in a table (one table/SAR)\n",
    "\n",
    "Recombined smoothed VH profile is saved in a table (one table/SAR)\n",
    "Output tables are named as following:\n",
    "\n",
    "'[(id_segment)_VH_(dteExe)_smoothed]'\n",
    "\n",
    "'[(id_segment)_dates_(dteExe)]'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb44ecd8-6b52-46fa-9efd-ddd86ab2f0e1",
   "metadata": {},
   "source": [
    "## Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2549e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime, pandas as pd\n",
    "sys.path.append(\"/home/gswinnen/SARSAR_Package_RenPri/code/\") # Localisation of SARSAR libraries\n",
    "sys.path.append(\"/home/gswinnen/SARSAR_Mattia/\")              # Localisation of change_detection module\n",
    "\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/\")                   # emplacement des modules RenPri\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/rme_chg_detection_module/\") # emplacement de la fonction de Mattia\n",
    "\n",
    "import changedetection\n",
    "from issep import sarsar_admin\n",
    "from os.path import join\n",
    "from lecture_ini import config\n",
    "from select_sites import sites_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4079f5d0-dbd7-46b7-b729-4a5c93a26e35",
   "metadata": {},
   "source": [
    "## Definition of the **change_date_detection** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_date_detection(sites, dteDebut, dteFin, dteExe):\n",
    "    \n",
    "    \"\"\" This function operates change date detection.\n",
    "        It uses 4-year VH_[orbit] and NDWI profiles to detect eventual change date over the last year of the considered 4-year period (dteDebut - dteFin).\n",
    "        The function adds tables to the DB containing change dates and VH recombined and smoothed profiles.\n",
    "    \n",
    "            Parameters (they are automatically read in \"sarsar.ini\" by the function \"config\"):\n",
    "                sites (list): list of sites (sar_id_segment) to process\n",
    "                dteDebut (date): date from which we need data (YYYY-MM-DD)\n",
    "                dteFin (date): date until which we need data (YYYY-MM-DD)\n",
    "                dteExe: processing/execution date (YYYYMMDD)\n",
    "            \"\"\"\n",
    "    \n",
    "    ## CONNECTION TO DB\n",
    "    # Define Database connection parameters\n",
    "    # NOTE: password is in ~/.pgpass\n",
    "\n",
    "    credentials = config(section='postgresql')\n",
    "    db_credentials = {\n",
    "        'host': credentials['host'],\n",
    "        'user': credentials['user'],\n",
    "        'db' : credentials['database']\n",
    "    }\n",
    "\n",
    "    # ALWAYS prepare env at the beginning\n",
    "    print('> Preparing env (DB credentials, etc)')\n",
    "    sarsar_admin.prepare_env(db_credentials)\n",
    "    \n",
    "    conn = sarsar_admin._create_or_get_db_connection()\n",
    "    cur = None\n",
    "    cur2 = None\n",
    "    \n",
    "    ## STARTING CHANGE DATE DETECTION\n",
    "\n",
    "    try:\n",
    "        import psycopg2.extras #allow communication with pgsql\n",
    "        cur = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "        cur2 = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "\n",
    "        # Liste les sar_id_segment pour lesquels j'ai des observations dans l'intervalle de dates\n",
    "#         strSQL = '''SELECT DISTINCT sar_id_segment \n",
    "#                     FROM sar_index_stats WHERE index_name NOT IN ('BI2','VV','SBI','NDVI','BI2_part1','BI','BAI','VH') \n",
    "#                     AND substring(index_name,1,2) != 'VV' AND acq_date BETWEEN '{0}' AND '{1}' \n",
    "#                     ORDER BY sar_id_segment;'''.format(dteDebut, dteFin)\n",
    "#         cur.execute(strSQL)\n",
    "#         sites = [item[0] for item in cur.fetchall()]\n",
    "\n",
    "        # DEBUG: force la liste\n",
    "    #        sites = ['62003-ISA-0007-01', '62063-ISA-0073-01', '62096-ISA-0056-01','52012-ISA-0010-01']\n",
    "#        print(\"DEBUG: {0} sites trouvÃ©s\".format(len(sites)))\n",
    "\n",
    "#        i_debug = 438             # DEBUG\n",
    "#        sites = sites[i_debug:]   # DEBUG\n",
    "\n",
    "    ## PREPARATION OF INPUTS FOR CHANGE DETECTION\n",
    "        for site in sites:\n",
    "#            i_debug += 1\n",
    "#            print(site, i_debug)  # DEBUG\n",
    "            dataframes = []\n",
    "            nomDataframe = ''\n",
    "            \n",
    "            # Selection of VH_\"orbit\" and NDWI 4-year profiles in the SAR_index_stats table\n",
    "            strSQL = '''SELECT sar_id_segment, index_name, acq_date, index_mean, pixel_count \n",
    "                        FROM sar_index_stats \n",
    "                        WHERE sar_id_segment = '{0}' AND index_name NOT IN ('BI2','VV','SBI','NDVI','BI2_part1','BI','BAI','VH') \n",
    "                        AND substring(index_name,1,2) != 'VV' AND acq_date BETWEEN '{1}' AND '{2}' \n",
    "                        ORDER BY sar_id_segment, index_name, acq_date;'''.format(site, dteDebut, dteFin)\n",
    "            cur.execute(strSQL)\n",
    "            result = cur.fetchall()\n",
    "\n",
    "            # Sequentially scans \"result\"\n",
    "            # For each new sar_id_segment/index_name, a pandas dataframe is created\n",
    "            # For a given site (sar_id_segment), the name of the created df are registered in a list\n",
    "            for row in result:\n",
    "                if nomDataframe not in ['{0}_S1_{1}_profile'.format(row['sar_id_segment'], row['index_name']), '{0}_S2_{1}_profile'.format(row['sar_id_segment'], row['index_name'])] :\n",
    "                    if nomDataframe != '':\n",
    "                        # If it exists, the current dataframe is registered in the list\n",
    "                        dataframes.append(df)\n",
    "\n",
    "                    # Creation of new df for VH_\"orbit\" indexes\n",
    "                    # NB: the df exist only within the execution of the program\n",
    "                    if row['index_name'] != 'NDWI2':\n",
    "                        nomDataframe = '{0}_S1_{1}_profile'.format(row['sar_id_segment'], row['index_name'])\n",
    "                        colDataframe = ['Date', 'Hour', row['index_name'].replace('VH', 'VH_'), 'Size']\n",
    "\n",
    "                        df = pd.DataFrame([(row['acq_date'].strftime(\"%Y-%m-%d\"), '06:00:00', row['index_mean'], row['pixel_count'])], columns = colDataframe)\n",
    "                    else:\n",
    "                        # Creation of new df for NDWI2 indexes\n",
    "                        # Do not process NDWI2 whose average index is 0 (outliers)\n",
    "                        if row['index_mean'] != 0:\n",
    "                            nomDataframe = '{0}_S2_{1}_profile'.format(row['sar_id_segment'], row['index_name'])\n",
    "                            colDataframe = ['Date', row['index_name']]\n",
    "\n",
    "                            df = pd.DataFrame([(row['acq_date'].strftime(\"%Y-%m-%d\"), row['index_mean'])], columns = colDataframe)\n",
    "                    # For a given site (sar_id_segment), the name of the created df are registered in a list\n",
    "                    df.name = nomDataframe\n",
    "\n",
    "                else:\n",
    "                    # Add line to the current df\n",
    "                    if row['index_name'] != 'NDWI2':\n",
    "                        df = df.append({'Date':row['acq_date'].strftime(\"%Y-%m-%d\"), 'Hour':'06:00:00', row['index_name'].replace('VH', 'VH_'):row['index_mean'], 'Size':row['pixel_count']} , ignore_index=True)\n",
    "                    else:\n",
    "                        df = df.append({'Date':row['acq_date'].strftime(\"%Y-%m-%d\"), row['index_name']:row['index_mean']} , ignore_index=True)\n",
    "\n",
    "            # Add the last df to the list of df available for the current site\n",
    "            dataframes.append(df)\n",
    "            \n",
    "\n",
    "    ## CHANGE DETECTION\n",
    "            # The change detection module is called with the list of dataframes and dteFin as inputs\n",
    "            results = changedetection.change_detection(dataframes, dteFin)\n",
    "\n",
    "    ## SAVING CHANGE DETECTION OUTPUTS IN TABLES\n",
    "            # The output (df) of the change detection are stored in tables\n",
    "            \n",
    "            # First, the recombined and smoothed VH profile is saved\n",
    "            if isinstance(results[1], pd.DataFrame):                       # We check if the change detection has returned a df\n",
    "                table_name = '{0}_VH_{1}_smoothed'.format(site, dteExe)\n",
    "                strSQL = 'DROP TABLE IF EXISTS \"{0}\" CASCADE;'.format(table_name)  # Surround the table name to tolerate numbers at the beginning and dashes in the middle\n",
    "                cur2.execute(strSQL)\n",
    "                conn.commit()\n",
    "\n",
    "                strSQL = 'CREATE TABLE IF NOT EXISTS \"{0}\" (dte DATE, indice NUMERIC);'.format(table_name)  #, ', '.join(type_valeurs))\n",
    "                cur2.execute(strSQL)\n",
    "\n",
    "                for index, row in results[1].iterrows():\n",
    "                    strSQL = 'INSERT INTO \"{0}\" (dte, indice) VALUES (\\'{1}\\', {2});'.format(table_name, index, row['VH'])  # 'Date' is the df index\n",
    "            #        print(strSQL)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                # Post all modifications\n",
    "                conn.commit()\n",
    "            else:\n",
    "                print(\"DEBUG: results[1] == 0\")\n",
    "\n",
    "            # Second, the change date(s) are saved (same logic)\n",
    "            table_name = '{0}_dates_{1}'.format(site, dteExe)\n",
    "            strSQL = 'DROP TABLE IF EXISTS \"{0}\" CASCADE;'.format(table_name) \n",
    "            cur2.execute(strSQL)\n",
    "            conn.commit()\n",
    "\n",
    "            strSQL = 'CREATE TABLE IF NOT EXISTS \"{0}\" (Change_date DATE);'.format(table_name)  #, ', '.join(type_valeurs))\n",
    "            cur2.execute(strSQL)\n",
    "\n",
    "            if isinstance(results[0], pd.DataFrame):\n",
    "                for index, row in results[0].iterrows():\n",
    "                    strSQL = 'INSERT INTO \"{0}\" (Change_date) VALUES (\\'{1}\\');'.format(table_name, index)  \n",
    "                    print(strSQL)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                conn.commit()\n",
    "            else:\n",
    "                print(\"DEBUG: results[0] == 0\")\n",
    "            \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if cur2 is not None:\n",
    "            cur2.close()\n",
    "        if cur is not None:\n",
    "            cur.close()\n",
    "\n",
    "    # ALWAYS release env at the end\n",
    "    print('> Releasing env')\n",
    "    sarsar_admin.release_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dc7dae-6b8d-4818-a317-c253db087775",
   "metadata": {},
   "source": [
    "## Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04310ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call config\n",
    "dates = config(section='dates')\n",
    "dteDebut = dates['deb']\n",
    "dteFin = dates['fin']\n",
    "dteExe = dates['exe']\n",
    "\n",
    "## Call sites_to_process\n",
    "lstSARs = sites_to_process(dteDebut, dteFin)\n",
    "\n",
    "## Call change_detection\n",
    "change_date_detection(lstSARs, dteDebut, dteFin, dteExe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff1ef8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
