{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15aa0d21",
   "metadata": {},
   "source": [
    "# C - TIME SERIES SMOOTHING\n",
    "### NO PRE-REQUIREMENT EXCEPT UPDATED SAR_INDEX_STATS TABLE\n",
    "### Can be run in parallel with (B)\n",
    "### This program carries out time-series gap filling and smoothing (gaussian filter) for a selection of indexes using the following function:\n",
    "#### smooth_time_serie(dteDebut, dteFin, dteExe)\n",
    "### For each SAR, this function operates the following steps:\n",
    "### 1) Listing of sentinel 2 for which we want to obtain smoothed profiles\n",
    "### 2) Selection of index raw data in the sar_index_stats tables and outlier removal for the period between dteDebut and dteFin\n",
    "### 3) Gap filling and smoothing\n",
    "### 4) Smoothed time series are saved in tables\n",
    "#### There is one table per index per site\n",
    "#### Tables are named as following: (id_segment)_(index)_(dteExe)_smoothed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6168c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime\n",
    "sys.path.append(\"/home/gswinnen/SARSAR_Package_RenPri/code/\") # emplacement des modules RenPri\n",
    "\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/\")                   # emplacement des modules RenPri\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/rme_chg_detection_module/\") # emplacement de la fonction de Mattia\n",
    "\n",
    "from issep import sarsar_admin\n",
    "from os.path import join\n",
    "from lecture_ini import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_time_serie(dteDebut, dteFin, dteExe):\n",
    "    \n",
    "    # List all indices\n",
    "    indices = ['BAI','BI','BI2','NDVI','SBI']\n",
    "        \n",
    "    # Define Database connection parameters\n",
    "    # NOTE: password is in ~/.pgpass\n",
    "    credentials = config(section='postgresql')\n",
    "\n",
    "    db_credentials = {\n",
    "        'host': credentials['host'],\n",
    "        'user': credentials['user'],\n",
    "        'db' : credentials['database']\n",
    "    }\n",
    "\n",
    "    # ALWAYS prepare env et the beginning\n",
    "    print('> Preparing env (DB credentials, etc)')\n",
    "    sarsar_admin.prepare_env(db_credentials)\n",
    "    \n",
    "    # Process all sar_id_segments\n",
    "    conn = sarsar_admin._create_or_get_db_connection()\n",
    "    cur = None\n",
    "\n",
    "    try:\n",
    "        import psycopg2.extras\n",
    "        cur = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "        cur.execute('SELECT DISTINCT sar_id_segment FROM sar_index_stats;')    \n",
    "        result = cur.fetchall()\n",
    "        for row in result:\n",
    "            sar_id_segment = dict(row)\n",
    "            \n",
    "            \n",
    "            for indice in indices :\n",
    "                print('> Processing smoothing for %s, %s' % (sar_id_segment, indice))\n",
    "                raw_profile = sarsar_admin.fetch_sar_index_stats_by_sar_id(sar_id_segment['sar_id_segment'], indice, dteDebut, dteFin )\n",
    "                \n",
    "                # Supprime les outliers du dataframe\n",
    "                no_outlier_profile = sarsar_admin.remove_outliers_from_stats(raw_profile)\n",
    "\n",
    "                # Lissage\n",
    "                smoothed_profile = sarsar_admin.compute_smoothed_time_series_stats(no_outlier_profile)\n",
    "\n",
    "                # transpose les deux arrays dans un dictionnaire tel qu'attendu pour la boucle suivante...\n",
    "                smoothed_dates = smoothed_profile[0]\n",
    "                smoothed_values = smoothed_profile[1]\n",
    "                smoothed_profile_dico = {}\n",
    "\n",
    "                for i in range(len(smoothed_dates)):\n",
    "                    smoothed_profile_dico[smoothed_dates[i].strftime(\"%Y-%m-%d\")] = smoothed_values[i]\n",
    "\n",
    "                # (re)crée LA table \"{sar_id_segment}_{indice}_{dteExe}_smoothed\" qui doit accueillir ces données\n",
    "                table_name = '{0}_{1}_{2}_smoothed'.format(sar_id_segment['sar_id_segment'], indice, dteExe)\n",
    "                strSQL = 'DROP TABLE IF EXISTS \"{0}\";'.format(table_name)  # Encadrer le nom de table pour tolérer les chiffres en début et les tirets au milieu\n",
    "                cur.execute(strSQL)\n",
    "                conn.commit()\n",
    "\n",
    "                strSQL = 'CREATE TABLE IF NOT EXISTS \"{0}\" (dte DATE, indice NUMERIC);'.format(table_name)  #, ', '.join(type_valeurs))\n",
    "                cur.execute(strSQL)\n",
    "\n",
    "                for item in smoothed_profile_dico:\n",
    "                    strSQL = 'INSERT INTO \"{0}\" (dte, indice) VALUES (\\'{1}\\', {2});'.format(table_name, item, smoothed_profile_dico[item])  # , (', '.join(champs)), str(tuple(valeurs)))\n",
    "                    cur.execute(strSQL)\n",
    "\n",
    "            # Poste toutes les modifications\n",
    "            conn.commit()\n",
    "            \n",
    "        cur.close()\n",
    "        \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if cur is not None:\n",
    "            cur.close()\n",
    "            \n",
    "    # ALWAYS release env at the end\n",
    "    print('> Releasing env')\n",
    "    sarsar_admin.release_env()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
