{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd35327",
   "metadata": {},
   "source": [
    "# C - TIME SERIES SMOOTHING\n",
    "**REQUIREMENT : (A)**\n",
    "\n",
    "Can be run in parallel with (B).\n",
    "\n",
    "This program carries out time-series gap filling and smoothing (gaussian filter) for a selection of indexes using the following function:\n",
    "\n",
    ">**smooth_time_serie(sites, dteDebut, dteFin, dteExe)**\n",
    "\n",
    "For each SAR, this function operates the following steps:\n",
    "\n",
    "**1) Listing of sentinel 2 indexes for which we want to obtain smoothed profiles**\n",
    "\n",
    "**2) Selection of index raw data in the sar_index_stats tables and outlier removal for the period between dteDebut and dteFin**\n",
    "\n",
    "**3) Gap filling and smoothing**\n",
    "\n",
    "**4) Smoothed time series are saved in tables**\n",
    "\n",
    "There is one table per index per site.\n",
    "\n",
    "Tables are named as following: (id_segment)_(index)_(dteExe)_smoothed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccffb52-0214-4e79-a083-acaf76f8567e",
   "metadata": {},
   "source": [
    "## Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e700d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime\n",
    "sys.path.append(\"/home/gswinnen/SARSAR_Package_RenPri/code/\") # Localisation of SARSAR libraries\n",
    "\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/\")                   # emplacement des modules RenPri\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/rme_chg_detection_module/\") # emplacement de la fonction de Mattia\n",
    "\n",
    "from issep import sarsar_admin\n",
    "from os.path import join\n",
    "from lecture_ini import config\n",
    "from select_sites import sites_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d9069-d727-4833-bae4-c8ded89c7c8a",
   "metadata": {},
   "source": [
    "## Definition of the **smooth_time_serie** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ed44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_time_serie(sites, dteDebut, dteFin, dteExe):\n",
    "    \"\"\" This function fills the gaps and smoothes index raw profiles using a gaussian filter over a given period (dteDebut-dteFin).\n",
    "        The function adds tables to the DB containing the resulting smoothed index time series.\n",
    "        \n",
    "            Parameters (they are automatically read in \"sarsar.ini\" by the function \"config\"):\n",
    "                sites (list): list of sites (sar_id_segment) to process\n",
    "                dteDebut (date): date from which we need data (YYYY-MM-DD)\n",
    "                dteFin (date): date until which we need data (YYYY-MM-DD)\n",
    "                dteExe: processing/execution date (YYYYMMDD)\n",
    "                \"\"\"\n",
    "    \n",
    "    ## DEFINING LIST OF INDEXES TO SMOOTH\n",
    "    indices = ['BAI','BI','BI2','NDVI','SBI']\n",
    "    \n",
    "    \n",
    "    ## CONNECTION TO DB    \n",
    "    # Define Database connection parameters\n",
    "    # NOTE: password is in ~/.pgpass\n",
    "    credentials = config(section='postgresql')\n",
    "\n",
    "    db_credentials = {\n",
    "        'host': credentials['host'],\n",
    "        'user': credentials['user'],\n",
    "        'db' : credentials['database']\n",
    "    }\n",
    "\n",
    "    # ALWAYS prepare env et the beginning\n",
    "    print('> Preparing env (DB credentials, etc)')\n",
    "    sarsar_admin.prepare_env(db_credentials)\n",
    "    \n",
    "    conn = sarsar_admin._create_or_get_db_connection()\n",
    "    cur = None\n",
    "    \n",
    "    ##CALCULATION OF SMOOTHED INDEX PROFILES\n",
    "\n",
    "    try:\n",
    "        import psycopg2.extras\n",
    "        cur = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "#         cur.execute('SELECT DISTINCT sar_id_segment FROM sar_index_stats;')    \n",
    "#         sites = cur.fetchall()\n",
    "        for site in sites:\n",
    "            #sar_id_segment = dict(site) # DEBUG : Why do we create a dictionnary?\n",
    "            \n",
    "            for indice in indices :\n",
    "                print('> Processing smoothing for %s, %s' % (site, indice))\n",
    "                # DEBUG : Why not \"site\" instead of \"sar_id_segment['sar_id_segment']\"\n",
    "                # Fetching raw index values over the given period\n",
    "#                raw_profile = sarsar_admin.fetch_sar_index_stats_by_sar_id(sar_id_segment['sar_id_segment'], indice, dteDebut, dteFin )\n",
    "                raw_profile = sarsar_admin.fetch_sar_index_stats_by_sar_id(site, indice, dteDebut, dteFin )\n",
    "                \n",
    "                # Removing outliers from raw profiles\n",
    "                no_outlier_profile = sarsar_admin.remove_outliers_from_stats(raw_profile)\n",
    "\n",
    "                # Smoothing time series\n",
    "                smoothed_profile = sarsar_admin.compute_smoothed_time_series_stats(no_outlier_profile)\n",
    "\n",
    "                # transposes the two arrays into a dictionary as expected for the next loop\n",
    "                smoothed_dates = smoothed_profile[0]\n",
    "                smoothed_values = smoothed_profile[1]\n",
    "                smoothed_profile_dico = {}\n",
    "                \n",
    "    ## SAVING SMOOTHED INDEX PROFILES IN TABLES\n",
    "                for i in range(len(smoothed_dates)):\n",
    "                    smoothed_profile_dico[smoothed_dates[i].strftime(\"%Y-%m-%d\")] = smoothed_values[i]\n",
    "\n",
    "                # (re)create the table \"{sar_id_segment}_{index}_{dteExe}_smoothed\" which should contain this data\n",
    "#                table_name = '{0}_{1}_{2}_smoothed'.format(sar_id_segment['sar_id_segment'], indice, dteExe)\n",
    "                table_name = '{0}_{1}_{2}_smoothed'.format(site, indice, dteExe)\n",
    "                strSQL = 'DROP TABLE IF EXISTS \"{0}\";'.format(table_name)  # Surround the table name to tolerate numbers at the beginning and dashes in the middle\n",
    "                cur.execute(strSQL)\n",
    "                conn.commit()\n",
    "\n",
    "                strSQL = 'CREATE TABLE IF NOT EXISTS \"{0}\" (dte DATE, indice NUMERIC);'.format(table_name)  #, ', '.join(type_valeurs))\n",
    "                cur.execute(strSQL)\n",
    "                \n",
    "                #Filling table\n",
    "                for item in smoothed_profile_dico:\n",
    "                    strSQL = 'INSERT INTO \"{0}\" (dte, indice) VALUES (\\'{1}\\', {2});'.format(table_name, item, smoothed_profile_dico[item])  # , (', '.join(champs)), str(tuple(valeurs)))\n",
    "                    cur.execute(strSQL)\n",
    "\n",
    "            # Post all modifications\n",
    "            conn.commit()\n",
    "            \n",
    "        cur.close()\n",
    "        \n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    finally:\n",
    "        if cur is not None:\n",
    "            cur.close()\n",
    "            \n",
    "    # ALWAYS release env at the end\n",
    "    print('> Releasing env')\n",
    "    sarsar_admin.release_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedaed40-4d75-4eef-a6da-d42598469655",
   "metadata": {},
   "source": [
    "## Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045590c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Call config\n",
    "dates = config(section='dates')\n",
    "dteDebut = dates['deb']\n",
    "dteFin = dates['fin']\n",
    "dteExe = dates['exe']\n",
    "\n",
    "## Call sites_to_process\n",
    "lstSARs = sites_to_process(dteDebut, dteFin)\n",
    "\n",
    "## Call smooth_time_serie\n",
    "smooth_time_serie(lstSARs, dteDebut, dteFin, dteExe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7c1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
