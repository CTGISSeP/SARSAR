{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4eeded1",
   "metadata": {},
   "source": [
    "# D - classification of change dates\n",
    "### REQUIREMENT: (B) and (C) to be run prior (D)\n",
    "### This program carries out the classification of the changement detected by program (B) using the following function:\n",
    "#### dates_change_classification(dteDebut, dteFin, dteChgEnd, dteExe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d789669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime, pandas as pd\n",
    "sys.path.append(\"/home/gswinnen/SARSAR_Package_RenPri/code/\") # emplacement des modules RenPri\n",
    "\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/\")                   # emplacement des modules RenPri\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/rme_chg_detection_module/\") # emplacement de la fonction de Mattia\n",
    "\n",
    "from issep import sarsar_admin\n",
    "from os.path import join\n",
    "from lecture_ini import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60777d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to convert formatted strings into date objects; on which intervals can be calculated.\n",
    "dateparse = lambda x: datetime.datetime.strptime(x, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ab6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_change_classification(dteDebut, dteFin, dteChgEnd, dteExe):\n",
    "\n",
    "    dates = config(section='dates')\n",
    "    nbrDays_S1 = int(dates['days_s1'])\n",
    "    nbrDays_S2 = int(dates['days_s2'])\n",
    "    \n",
    "    # Define Database connection parameters\n",
    "    # NOTE: password is in ~/.pgpass\n",
    "    credentials = config(section='postgresql')\n",
    "\n",
    "    db_credentials = {\n",
    "        'host': credentials['host'],\n",
    "        'user': credentials['user'],\n",
    "        'db' : credentials['database']\n",
    "    }\n",
    "\n",
    "    # ALWAYS prepare env et the beginning\n",
    "    print('> Preparing env (DB credentials, etc)')\n",
    "    sarsar_admin.prepare_env(db_credentials)\n",
    "\n",
    "    # Ouvre la connexion à la DB\n",
    "    conn = sarsar_admin._create_or_get_db_connection()\n",
    "    cur = None\n",
    "\n",
    "    # Liste de dictionnaires 'sar_id_segment'\n",
    "    sar_id_segments = []\n",
    "\n",
    "    try:\n",
    "        import psycopg2.extras\n",
    "        cur = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "        cur2 = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "\n",
    "        ## Creation de la table résultat, lecture des dates de changements, \n",
    "        ## calculs des amplitudes dans les indices lorsqu'il y a une date de changement\n",
    "\n",
    "        table_name = 'classif_bimestrial_chg_dates'\n",
    "\n",
    "        # strSQL = 'DROP TABLE IF EXISTS {0};'.format(table_name)\n",
    "        # cur.execute(strSQL)\n",
    "        # conn.commit()\n",
    "\n",
    "        strSQL = 'CREATE TABLE IF NOT EXISTS \"{0}\" (ID_Segment TEXT, dteExe DATE, dteChgEnd DATE, date DATE, NDVI_amplitude NUMERIC(4,3), BAI_amplitude NUMERIC(4,3), VH_amplitude NUMERIC(4,3), vegetation INTEGER, soil INTEGER, building INTEGER, nImages_a INTEGER, nImages_p INTEGER);'.format(table_name)\n",
    "        cur.execute(strSQL)\n",
    "\n",
    "        # Liste les sar_id_segment pour lesquels j'ai des observations dans l'intervalle de dates\n",
    "        strSQL = '''SELECT DISTINCT sar_id_segment \n",
    "                    FROM sar_index_stats WHERE index_name NOT IN ('BI2','VV','SBI','NDVI','BI2_part1','BI','BAI','VH') \n",
    "                    AND substring(index_name,1,2) != 'VV' AND acq_date BETWEEN '{0}' AND '{1}' \n",
    "                    ORDER BY sar_id_segment;'''.format(dteDebut, dteFin)\n",
    "        cur.execute(strSQL)\n",
    "        sites = [item[0] for item in cur.fetchall()]\n",
    "\n",
    "        # DEBUG: force la liste\n",
    "    #        sites = ['62003-ISA-0007-01', '62063-ISA-0073-01', '62096-ISA-0056-01','52012-ISA-0010-01']\n",
    "\n",
    "    #    i_debug = 0               # DEBUG\n",
    "    #    sites = sites[i_debug:]   # DEBUG\n",
    "\n",
    "        # Cherche les dates de changements détectées par 02_new (réunit le travail de 02 et 03 dans postgres)\n",
    "        for site in sites:\n",
    "    #        i_debug += 1\n",
    "    #        print(site, i_debug)  # DEBUG\n",
    "\n",
    "            strSQL = 'SELECT * FROM \"{0}\" ORDER BY change_date;'.format('{0}_dates_{1}'.format(site, dteExe))\n",
    "            cur.execute(strSQL)\n",
    "\n",
    "            # S'il y a au moins un changement détecté\n",
    "            if cur.rowcount > 0:\n",
    "\n",
    "                # Converti le fetchall en liste\n",
    "                dates = [item[0] for item in cur.fetchall()]  # .strftime(\"%Y-%m-%d\")\n",
    "\n",
    "                # Converti la liste en dataframe\n",
    "                listeDates = pd.DataFrame (dates, columns = ['Change date'])\n",
    "\n",
    "    #            print(listeDates)  # DEBUG\n",
    "\n",
    "                # Ajoute au dataframe des colonnes calculées\n",
    "                listeDates['a_debut_S2'] = listeDates['Change date']\n",
    "                listeDates['a_fin_S2'] = listeDates['Change date'] + datetime.timedelta(days = nbrDays_S2)\n",
    "                listeDates['p_debut_S2'] = listeDates['a_debut_S2'] - datetime.timedelta(days = 365)\n",
    "                listeDates['p_fin_S2'] = listeDates['a_fin_S2'] - datetime.timedelta(days = 365)\n",
    "\n",
    "                listeDates['a_debut_S1'] = listeDates['Change date']\n",
    "                listeDates['a_fin_S1'] = listeDates['Change date'] + datetime.timedelta(days = nbrDays_S1)\n",
    "                listeDates['p_debut_S1'] = listeDates['a_debut_S1'] - datetime.timedelta(days = 365)\n",
    "                listeDates['p_fin_S1'] = listeDates['a_fin_S1'] - datetime.timedelta(days = 365)\n",
    "\n",
    "                # For each date of change, check that we have the smoothed data for each indice; \n",
    "                # and calculate the difference for the same period compared to the previous year.\n",
    "                for i in listeDates.index:\n",
    "                    NDVI_amplitude = None\n",
    "                    BAI_amplitude = None\n",
    "                    VH_amplitude = None\n",
    "                    vegetation = None\n",
    "                    soil = None\n",
    "                    building = None\n",
    "\n",
    "    # NDVI__________________\n",
    "                    # Va rechercher les indices NDVI \"lissés\" dans la DB\n",
    "                    table_smooth = '{0}_NDVI_{1}_smoothed'.format(site, dteExe)\n",
    "\n",
    "                    # Vérifie si on a pour ce site/indice une table \"smoothed\" contenant des valeurs pour notre intervalle de dates\n",
    "                    strSQL = \"SELECT EXISTS (SELECT * FROM information_schema.tables WHERE table_name = '{0}');\".format(table_smooth)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                    # Si on a des NDVI \"smoothés\", on en demande la valeur moyenne\n",
    "                    NDVI_EXISTS = cur2.fetchone()[0]\n",
    "\n",
    "                    if NDVI_EXISTS == True:\n",
    "                        strSQL = 'SELECT a.moyenne, p.moyenne as moyenne_p, ROUND(a.moyenne-p.moyenne, 3) AS moyenne_chg FROM (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{1}\\' AND \\'{2}\\') a, (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{3}\\' AND \\'{4}\\') p;'.format(table_smooth, listeDates['a_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['a_fin_S2'][i].strftime('%Y-%m-%d'), listeDates['p_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['p_fin_S2'][i].strftime('%Y-%m-%d'))\n",
    "                        cur2.execute(strSQL)\n",
    "                        NDVI_amplitude = cur2.fetchone()['moyenne_chg']\n",
    "\n",
    "    # BAI__________________\n",
    "                    # Va rechercher les indices BAI \"lissés\" dans la DB\n",
    "                    table_smooth = '{0}_BAI_{1}_smoothed'.format(site, dteExe)\n",
    "\n",
    "#                    print('table_smooth =', table_smooth)\n",
    "\n",
    "                    # Vérifie si on a pour ce site/indice une table \"smoothed\" contenant des valeurs pour notre intervalle de dates\n",
    "                    strSQL = \"SELECT EXISTS (SELECT * FROM information_schema.tables WHERE table_name = '{0}');\".format(table_smooth)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                    # Si on a des BAI \"smoothés\", on en demande la valeur moyenne\n",
    "                    BAI_EXISTS = cur2.fetchone()[0]\n",
    "\n",
    "                    if BAI_EXISTS == True:\n",
    "                        strSQL = 'SELECT a.moyenne, p.moyenne as moyenne_p, ROUND(a.moyenne-p.moyenne, 3) AS moyenne_chg FROM (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{1}\\' AND \\'{2}\\') a, (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{3}\\' AND \\'{4}\\') p;'.format(table_smooth, listeDates['a_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['a_fin_S2'][i].strftime('%Y-%m-%d'), listeDates['p_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['p_fin_S2'][i].strftime('%Y-%m-%d'))\n",
    "                        print(strSQL)\n",
    "                        cur2.execute(strSQL)\n",
    "                        BAI_amplitude = cur2.fetchone()['moyenne_chg']\n",
    "\n",
    "    # VH__________________\n",
    "                    # Va rechercher les indices NDVI \"lissés\" dans la DB\n",
    "                    table_smooth = '{0}_VH_{1}_smoothed'.format(site, dteExe)\n",
    "\n",
    "                    # Vérifie si on a pour ce site/indice une table \"smoothed\" contenant des valeurs pour notre intervalle de dates\n",
    "                    strSQL = \"SELECT EXISTS (SELECT * FROM information_schema.tables WHERE table_name = '{0}');\".format(table_smooth)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                    # Si on a des VH \"smoothés\", on en demande la valeur moyenne\n",
    "                    VH_EXISTS = cur2.fetchone()[0]\n",
    "\n",
    "                    if VH_EXISTS == True:\n",
    "                        strSQL = 'SELECT a.moyenne, p.moyenne as moyenne_p, ROUND(a.moyenne-p.moyenne, 3) AS moyenne_chg FROM (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{1}\\' AND \\'{2}\\') a, (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{3}\\' AND \\'{4}\\') p;'.format(table_smooth, listeDates['a_debut_S1'][i].strftime('%Y-%m-%d'), listeDates['a_fin_S1'][i].strftime('%Y-%m-%d'), listeDates['p_debut_S1'][i].strftime('%Y-%m-%d'), listeDates['p_fin_S1'][i].strftime('%Y-%m-%d'))\n",
    "                        cur2.execute(strSQL)\n",
    "                        VH_amplitude = cur2.fetchone()['moyenne_chg']\n",
    "\n",
    "\n",
    "    # Vérifie le nombre d'images réelles sur lesquelles la détection s'est opérée (représentativité...)\n",
    "                    nImages_a = 0\n",
    "                    nImages_p = 0\n",
    "\n",
    "                    strSQL = 'SELECT count(*) FROM sar_index_stats WHERE sar_id_segment = \\'{0}\\' AND index_name = \\'NDVI\\' AND acq_date BETWEEN \\'{1}\\' AND \\'{2}\\';'.format(site, listeDates['a_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['a_fin_S2'][i].strftime('%Y-%m-%d'))\n",
    "                    cur2.execute(strSQL)\n",
    "                    nImages_a = cur2.fetchone()[0]\n",
    "\n",
    "                    strSQL = 'SELECT count(*) FROM sar_index_stats WHERE sar_id_segment = \\'{0}\\' AND index_name = \\'NDVI\\' AND acq_date BETWEEN \\'{1}\\' AND \\'{2}\\';'.format(site, listeDates['p_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['p_fin_S2'][i].strftime('%Y-%m-%d'))\n",
    "                    cur2.execute(strSQL)\n",
    "                    nImages_p = cur2.fetchone()[0]\n",
    "\n",
    "\n",
    "    # Qualification des changementd__________\n",
    "\n",
    "                    # changements de l'indice NDVI\n",
    "                    if NDVI_amplitude != None:\n",
    "                        if NDVI_amplitude >= 0.1:\n",
    "                            vegetation = 2  # « Augmentation végétation »\n",
    "\n",
    "                        elif NDVI_amplitude <= -0.1:\n",
    "                            vegetation = 3  # « Diminution végétation »\n",
    "\n",
    "                        else:\n",
    "                            vegetation = 0  # « Pas de changement végétation »\n",
    "\n",
    "\n",
    "                    # changements de l'indice BAI\n",
    "                    if BAI_amplitude != None:\n",
    "\n",
    "                        if abs(BAI_amplitude) >= 0.05:\n",
    "                            soil = 1  # « Changement de sol »\n",
    "\n",
    "                        else:\n",
    "                            soil = 0  # « Pas de changement sol »\n",
    "\n",
    "\n",
    "                    # changements de l'indice VH\n",
    "                    if VH_amplitude != None:\n",
    "                        if VH_amplitude >= 0.135:\n",
    "                            building = 2  # « Augmentation bâtiment »\n",
    "\n",
    "                        elif VH_amplitude <= -0.135:\n",
    "                            building = 3  # « Diminution bâtiment »\n",
    "\n",
    "                        else:\n",
    "                            building = 0  # « Pas de changement bâtiment »\n",
    "\n",
    "                    strSQL = '''INSERT INTO {0} (ID_Segment, dteExe, dteChgEnd, date, NDVI_amplitude, BAI_amplitude, VH_amplitude, vegetation, soil, building, nImages_a, nImages_p) \n",
    "                                VALUES (\\'{1}\\', \\'{2}\\', \\'{3}\\', \\'{4}\\', {5}, {6}, {7}, {8}, {9}, {10}, \\'{11}\\', \\'{12}\\');'''.format(table_name, site, f'{dteExe[0:4]}-{dteExe[4:6]}-{dteExe[6:]}', dteChgEnd, listeDates['Change date'][i].strftime('%Y-%m-%d'), NDVI_amplitude, BAI_amplitude, VH_amplitude, vegetation, soil, building, nImages_a, nImages_p)\n",
    "    #                print(strSQL)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                    # Poste toutes les modifications\n",
    "                    conn.commit()\n",
    "\n",
    "        cur2.close()\n",
    "        cur.close()\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        \n",
    "    finally:\n",
    "        if cur2 is not None:\n",
    "            cur2.close()\n",
    "\n",
    "        if cur is not None:\n",
    "            cur.close()\n",
    "            \n",
    "    # ALWAYS release env at the end\n",
    "    print('> Releasing env')\n",
    "    sarsar_admin.release_env()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
