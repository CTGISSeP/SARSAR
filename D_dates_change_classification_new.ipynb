{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8941e52",
   "metadata": {},
   "source": [
    "# D - classification of change dates\n",
    "\n",
    "**REQUIREMENT: (A), (B) and (C)**\n",
    "\n",
    "This program carries out the classification of the changement detected by program (B) using the following function:\n",
    "\n",
    "> **dates_change_classification(sites, dteChgEnd, dteExe)**\n",
    "\n",
    "This function operates the following step:\n",
    "\n",
    "**1) Creation/Determination of the result table**\n",
    "\n",
    "This table is named **classif_bimestrial_chg_dates**\n",
    "\n",
    "**2) For each site, reseach of change date potentially detected by script (B)**\n",
    "\n",
    "Change dates are stored in table named as following '{0}_dates_{1}'.format(site, dteExe).\n",
    "\n",
    "If there is no change date for a site, the related table is just empty.\n",
    "\n",
    "**3) For each site, for each of its change date, calculation of relevant periods of investigation from change dates**\n",
    "\n",
    "For S1 indexes (VH), their average over ((change date) - (change date + 30 days)) will be compared to their average over the same period the year before (((change date) - (change date + 30 days)) - 1 year).\n",
    "\n",
    "For S2 indexes (NDVI, BAI), their average over ((change date) - (change date + 60 days)) will be compared to their average over the same period the year before (((change date) - (change date + 60 days)) - 1 year).\n",
    "\n",
    "\n",
    "**4) For each site, for each of its change date, calculation of index averages over these relevant periods and their amplitude**\n",
    "\n",
    "For a given index, its amplitude is its variation (difference) between the \"current\" period and the same period the year before.\n",
    "\n",
    "**5) For each site, for each of its change date, calculation of the number of S2 which were exploitable over these relevant periods**\n",
    "\n",
    "This information is later used for the assessment of change confidence (G).\n",
    "\n",
    "\n",
    "**6) For each site, for each of its change date, caracterisation of changes based on index averages**\n",
    "\n",
    "Vegetation change caracterisation is based on NDVI analysis.\n",
    "\n",
    "Soil change caracterisation is based on BAI analysis.\n",
    "\n",
    "Building change caracterisation is based on VH analysis.\n",
    "\n",
    "**Code interpretation key**\n",
    "\n",
    "> 0 No change\n",
    "\n",
    "> 1 Change (no additional information)\n",
    "\n",
    "> 2 Increase\n",
    "\n",
    "> 3 Decrease\n",
    "\n",
    "> 4 Possible change (no additional information)\n",
    "\n",
    "> 5 Possible increase\n",
    "\n",
    "> 6 Possible decrease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4b3613-da10-4782-b218-8a9b1b442c29",
   "metadata": {},
   "source": [
    "## Import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime, pandas as pd\n",
    "sys.path.append(\"/home/gswinnen/SARSAR_Package_RenPri/code/\") # Localisation of SARSAR libraries\n",
    "\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/\")                   # emplacement des modules RenPri\n",
    "#sys.path.append(\"/home/issep/sarsar-issep/SARSAR_utils/rme_chg_detection_module/\") # emplacement de la fonction de Mattia\n",
    "\n",
    "from issep import sarsar_admin\n",
    "from os.path import join\n",
    "from lecture_ini import config\n",
    "from select_sites import sites_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a9313-e3d7-483f-a60e-5492f46e6b22",
   "metadata": {},
   "source": [
    "## Definition of the **change_date_classfication** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75458e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to convert formatted strings into date objects; on which intervals can be calculated.\n",
    "dateparse = lambda x: datetime.datetime.strptime(x, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3852bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_date_classification(sites, dteChgEnd, dteExe):\n",
    "    \"\"\" This function classifies/determines the type of change which occurs at the detected change dates, either vegetation, soil or building change.\n",
    "        Results of this function are returned in the following table: \"classif_bimestrial_chg_dates\".\n",
    "        \n",
    "            Parameters (they are automatically read in \"sarsar.ini\" by the function \"config\"):\n",
    "                sites (list): list of sites (sar_id_segment) to process\n",
    "                dteChgEnd (date): maximum change date (YYYY-MM-DD)\n",
    "                dteExe: processing/execution date (YYYYMMDD)\n",
    "                \"\"\"\n",
    "    ##READING PARAMETERS IN SARSAR.IN with CONFIG\n",
    "    \n",
    "    dates = config(section='dates')\n",
    "    nbrDays_S1 = int(dates['days_s1'])\n",
    "    nbrDays_S2 = int(dates['days_s2'])\n",
    "    \n",
    "    ## CONNECTION TO DB\n",
    "    # Define Database connection parameters\n",
    "    # NOTE: password is in ~/.pgpass\n",
    "    credentials = config(section='postgresql')\n",
    "\n",
    "    db_credentials = {\n",
    "        'host': credentials['host'],\n",
    "        'user': credentials['user'],\n",
    "        'db' : credentials['database']\n",
    "    }\n",
    "\n",
    "    # ALWAYS prepare env et the beginning\n",
    "    print('> Preparing env (DB credentials, etc)')\n",
    "    sarsar_admin.prepare_env(db_credentials)\n",
    "\n",
    "    conn = sarsar_admin._create_or_get_db_connection()\n",
    "    cur = None\n",
    "\n",
    "    ## STARTING CHANGE DATE CLASSIFICATION\n",
    "\n",
    "    try:\n",
    "        import psycopg2.extras\n",
    "        cur = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "        cur2 = conn.cursor(cursor_factory = psycopg2.extras.DictCursor)\n",
    "\n",
    "    ## (RE-)CREATION OF THE RESULT TABLE\n",
    "\n",
    "        table_name = 'classif_bimestrial_chg_dates'\n",
    "\n",
    "        strSQL = 'CREATE TABLE IF NOT EXISTS \"{0}\" (ID_Segment TEXT, dteExe DATE, dteChgEnd DATE, date DATE, NDVI_amplitude NUMERIC(4,3), BAI_amplitude NUMERIC(4,3), VH_amplitude NUMERIC(4,3), vegetation INTEGER, soil INTEGER, building INTEGER, nImages_a INTEGER, nImages_p INTEGER);'.format(table_name)\n",
    "        cur.execute(strSQL)\n",
    "\n",
    "#         # Liste les sar_id_segment pour lesquels j'ai des observations dans l'intervalle de dates\n",
    "#         strSQL = '''SELECT DISTINCT sar_id_segment \n",
    "#                     FROM sar_index_stats WHERE index_name NOT IN ('BI2','VV','SBI','NDVI','BI2_part1','BI','BAI','VH') \n",
    "#                     AND substring(index_name,1,2) != 'VV' AND acq_date BETWEEN '{0}' AND '{1}' \n",
    "#                     ORDER BY sar_id_segment;'''.format(dteDebut, dteFin)\n",
    "#         cur.execute(strSQL)\n",
    "#         sites = [item[0] for item in cur.fetchall()]\n",
    "\n",
    "        # DEBUG: force la liste\n",
    "    #        sites = ['62003-ISA-0007-01', '62063-ISA-0073-01', '62096-ISA-0056-01','52012-ISA-0010-01']\n",
    "\n",
    "    #    i_debug = 0               # DEBUG\n",
    "    #    sites = sites[i_debug:]   # DEBUG\n",
    "    \n",
    "\n",
    "    ## FETCHING CHANGE DATES RETURNING BY CHANGE DETECTION (B)\n",
    "        for site in sites:\n",
    "    #        i_debug += 1\n",
    "    #        print(site, i_debug)  # DEBUG\n",
    "\n",
    "            strSQL = 'SELECT * FROM \"{0}\" ORDER BY change_date;'.format('{0}_dates_{1}'.format(site, dteExe))\n",
    "            cur.execute(strSQL)\n",
    "            \n",
    "    ## INDEX AMPLITUDE CALCULATION\n",
    "            # If there is at least one change date\n",
    "            if cur.rowcount > 0:\n",
    "\n",
    "                # Fetchall is converted into a list\n",
    "                dates = [item[0] for item in cur.fetchall()]  # .strftime(\"%Y-%m-%d\")\n",
    "\n",
    "                # List is converted into a dataframe (df)\n",
    "                listeDates = pd.DataFrame (dates, columns = ['Change date'])\n",
    "    #            print(listeDates)  # DEBUG\n",
    "\n",
    "                # Calculation of periods over which index amplitude will be calculted\n",
    "                # Period limits are added to the df in new columns\n",
    "                listeDates['a_debut_S2'] = listeDates['Change date']\n",
    "                listeDates['a_fin_S2'] = listeDates['Change date'] + datetime.timedelta(days = nbrDays_S2)\n",
    "                listeDates['p_debut_S2'] = listeDates['a_debut_S2'] - datetime.timedelta(days = 365)\n",
    "                listeDates['p_fin_S2'] = listeDates['a_fin_S2'] - datetime.timedelta(days = 365)\n",
    "\n",
    "                listeDates['a_debut_S1'] = listeDates['Change date']\n",
    "                listeDates['a_fin_S1'] = listeDates['Change date'] + datetime.timedelta(days = nbrDays_S1)\n",
    "                listeDates['p_debut_S1'] = listeDates['a_debut_S1'] - datetime.timedelta(days = 365)\n",
    "                listeDates['p_fin_S1'] = listeDates['a_fin_S1'] - datetime.timedelta(days = 365)\n",
    "\n",
    "                # For each change date, check that the smoothed data for each indice is available; \n",
    "                # and calculate amplitude as the difference between index averaged value over the a-period compared to its value over the same period a year earlier (p-period).\n",
    "                \n",
    "                # Initialisation of variabkes\n",
    "                for i in listeDates.index:\n",
    "                    NDVI_amplitude = None\n",
    "                    BAI_amplitude = None\n",
    "                    VH_amplitude = None\n",
    "                    vegetation = None\n",
    "                    soil = None\n",
    "                    building = None\n",
    "\n",
    "    # NDVI__________________\n",
    "                    # Fetch NDVI smoothed table in DB\n",
    "                    table_smooth = '{0}_NDVI_{1}_smoothed'.format(site, dteExe)\n",
    "\n",
    "                    # Check if table exists\n",
    "                    strSQL = \"SELECT EXISTS (SELECT * FROM information_schema.tables WHERE table_name = '{0}');\".format(table_smooth)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                    # If table exists and contains values, calculate NDVI amplitude\n",
    "                    NDVI_EXISTS = cur2.fetchone()[0]\n",
    "\n",
    "                    if NDVI_EXISTS == True:\n",
    "                        strSQL = 'SELECT a.moyenne, p.moyenne as moyenne_p, ROUND(a.moyenne-p.moyenne, 3) AS moyenne_chg FROM (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{1}\\' AND \\'{2}\\') a, (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{3}\\' AND \\'{4}\\') p;'.format(table_smooth, listeDates['a_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['a_fin_S2'][i].strftime('%Y-%m-%d'), listeDates['p_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['p_fin_S2'][i].strftime('%Y-%m-%d'))\n",
    "                        cur2.execute(strSQL)\n",
    "                        NDVI_amplitude = cur2.fetchone()['moyenne_chg']\n",
    "\n",
    "    # BAI__________________\n",
    "                    # Fetch NDVI smoothed table in DB\n",
    "                    table_smooth = '{0}_BAI_{1}_smoothed'.format(site, dteExe)\n",
    "\n",
    "                    # Check if table exists\n",
    "                    strSQL = \"SELECT EXISTS (SELECT * FROM information_schema.tables WHERE table_name = '{0}');\".format(table_smooth)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                    # If table exists and contains values, calculate BAI amplitude\n",
    "                    BAI_EXISTS = cur2.fetchone()[0]\n",
    "\n",
    "                    if BAI_EXISTS == True:\n",
    "                        strSQL = 'SELECT a.moyenne, p.moyenne as moyenne_p, ROUND(a.moyenne-p.moyenne, 3) AS moyenne_chg FROM (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{1}\\' AND \\'{2}\\') a, (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{3}\\' AND \\'{4}\\') p;'.format(table_smooth, listeDates['a_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['a_fin_S2'][i].strftime('%Y-%m-%d'), listeDates['p_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['p_fin_S2'][i].strftime('%Y-%m-%d'))\n",
    "                        print(strSQL)\n",
    "                        cur2.execute(strSQL)\n",
    "                        BAI_amplitude = cur2.fetchone()['moyenne_chg']\n",
    "\n",
    "    # VH__________________\n",
    "                    # Fetch NDVI smoothed table in DB\n",
    "                    table_smooth = '{0}_VH_{1}_smoothed'.format(site, dteExe)\n",
    "\n",
    "                    # Check if table exists\n",
    "                    strSQL = \"SELECT EXISTS (SELECT * FROM information_schema.tables WHERE table_name = '{0}');\".format(table_smooth)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                    # If table exists and contains values, calculate VH amplitude\n",
    "                    VH_EXISTS = cur2.fetchone()[0]\n",
    "\n",
    "                    if VH_EXISTS == True:\n",
    "                        strSQL = 'SELECT a.moyenne, p.moyenne as moyenne_p, ROUND(a.moyenne-p.moyenne, 3) AS moyenne_chg FROM (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{1}\\' AND \\'{2}\\') a, (SELECT avg(indice) as moyenne FROM \"{0}\" WHERE dte BETWEEN \\'{3}\\' AND \\'{4}\\') p;'.format(table_smooth, listeDates['a_debut_S1'][i].strftime('%Y-%m-%d'), listeDates['a_fin_S1'][i].strftime('%Y-%m-%d'), listeDates['p_debut_S1'][i].strftime('%Y-%m-%d'), listeDates['p_fin_S1'][i].strftime('%Y-%m-%d'))\n",
    "                        cur2.execute(strSQL)\n",
    "                        VH_amplitude = cur2.fetchone()['moyenne_chg']\n",
    "\n",
    "\n",
    "    ## CALCULATED S2 IMAGES AVAILABILITY\n",
    "    \n",
    "                    nImages_a = 0\n",
    "                    nImages_p = 0\n",
    "\n",
    "                    strSQL = 'SELECT count(*) FROM sar_index_stats WHERE sar_id_segment = \\'{0}\\' AND index_name = \\'NDVI\\' AND acq_date BETWEEN \\'{1}\\' AND \\'{2}\\';'.format(site, listeDates['a_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['a_fin_S2'][i].strftime('%Y-%m-%d'))\n",
    "                    cur2.execute(strSQL)\n",
    "                    nImages_a = cur2.fetchone()[0]\n",
    "\n",
    "                    strSQL = 'SELECT count(*) FROM sar_index_stats WHERE sar_id_segment = \\'{0}\\' AND index_name = \\'NDVI\\' AND acq_date BETWEEN \\'{1}\\' AND \\'{2}\\';'.format(site, listeDates['p_debut_S2'][i].strftime('%Y-%m-%d'), listeDates['p_fin_S2'][i].strftime('%Y-%m-%d'))\n",
    "                    cur2.execute(strSQL)\n",
    "                    nImages_p = cur2.fetchone()[0]\n",
    "\n",
    "\n",
    "    ## CARACTERIZATION OF CHANGE DATE\n",
    "\n",
    "                    # Vegetation change\n",
    "                    if NDVI_amplitude != None:\n",
    "                        if NDVI_amplitude >= 0.1:\n",
    "                            vegetation = 2  # « Increase in vegetation »\n",
    "\n",
    "                        elif NDVI_amplitude <= -0.1:\n",
    "                            vegetation = 3  # « Decrease in vegetation  »\n",
    "\n",
    "                        else:\n",
    "                            vegetation = 0  # « No change in vegetation »\n",
    "\n",
    "                    # Soil change\n",
    "                    if BAI_amplitude != None:\n",
    "\n",
    "                        if abs(BAI_amplitude) >= 0.05:\n",
    "                            soil = 1  # « Change in soil »\n",
    "\n",
    "                        else:\n",
    "                            soil = 0  # « No change in soil »\n",
    "\n",
    "                    # Building change\n",
    "                    if VH_amplitude != None:\n",
    "                        if VH_amplitude >= 0.135:\n",
    "                            building = 2  # « Increase in building »\n",
    "\n",
    "                        elif VH_amplitude <= -0.135:\n",
    "                            building = 3  # « Decrease in building »\n",
    "\n",
    "                        else:\n",
    "                            building = 0  # « No change in building »\n",
    "                            \n",
    "    ## SAVING RESULTS\n",
    "                    # Inserting results in the result table\n",
    "\n",
    "                    strSQL = '''INSERT INTO {0} (ID_Segment, dteExe, dteChgEnd, date, NDVI_amplitude, BAI_amplitude, VH_amplitude, vegetation, soil, building, nImages_a, nImages_p) \n",
    "                                VALUES (\\'{1}\\', \\'{2}\\', \\'{3}\\', \\'{4}\\', {5}, {6}, {7}, {8}, {9}, {10}, \\'{11}\\', \\'{12}\\');'''.format(table_name, site, f'{dteExe[0:4]}-{dteExe[4:6]}-{dteExe[6:]}', dteChgEnd, listeDates['Change date'][i].strftime('%Y-%m-%d'), NDVI_amplitude, BAI_amplitude, VH_amplitude, vegetation, soil, building, nImages_a, nImages_p)\n",
    "    #                print(strSQL)\n",
    "                    cur2.execute(strSQL)\n",
    "\n",
    "                    # Posting all modifications\n",
    "                    conn.commit()\n",
    "\n",
    "        cur2.close()\n",
    "        cur.close()\n",
    "\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        \n",
    "    finally:\n",
    "        if cur2 is not None:\n",
    "            cur2.close()\n",
    "\n",
    "        if cur is not None:\n",
    "            cur.close()\n",
    "            \n",
    "    # ALWAYS release env at the end\n",
    "    print('> Releasing env')\n",
    "    sarsar_admin.release_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae728b58-52f9-472f-b4c5-d8634e1bd6a6",
   "metadata": {},
   "source": [
    "## Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15d690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call config\n",
    "dates = config(section='dates')\n",
    "dteDebut = dates['deb']\n",
    "dteFin = dates['fin']\n",
    "dteExe = dates['exe']\n",
    "dteChgEnd = dates['chg_end']\n",
    "\n",
    "## Call sites_to_process\n",
    "lstSARs = sites_to_process(dteDebut, dteFin)\n",
    "\n",
    "## Call dates_change_classification\n",
    "change_date_classification(lstSARs, dteChgEnd, dteExe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b2580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
